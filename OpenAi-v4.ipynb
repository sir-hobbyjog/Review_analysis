{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"rt_reviews_cleaned_with_names.csv\")\n",
    "\n",
    "# Group reviews by movie\n",
    "grouped_reviews = df.groupby('movie_title')['cleaned_review'].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    # Simple token count approximation\n",
    "    return len(text.split())\n",
    "\n",
    "def summarize_reviews(reviews):\n",
    "    reviews_text = ' '.join(reviews)\n",
    "    reviews_length = count_tokens(reviews_text)\n",
    "\n",
    "    # Use OpenAI API to summarize the reviews\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"Summarize the following movie reviews in no more than 200 words. \"\n",
    "            \"First, state what most viewers are saying. \"\n",
    "            \"Second, mention what some viewers are saying. \"\n",
    "            \"Third, provide the overall sentiment of the reviews. Be concise and avoid repetition.\"\n",
    "            \"Finally, provide a rating for each movie on a scale of 0-100:\\n\\n\"\n",
    "            f\"{reviews_text}\"\n",
    "        )}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                max_tokens=400\n",
    "            )\n",
    "            break  # Break out of the loop if the request is successful\n",
    "        except openai.error.RateLimitError as e:\n",
    "            # Extract the retry-after time from the error message and sleep for that duration\n",
    "            retry_after = e.headers.get(\"Retry-After\", 60)\n",
    "            print(f\"Rate limit exceeded. Retrying after {retry_after} seconds.\")\n",
    "            time.sleep(float(retry_after))\n",
    "\n",
    "    summary = response.choices[0].message['content'].strip()\n",
    "    return summary, reviews_length\n",
    "\n",
    "def manage_rate_limit(current_tokens, max_tokens_per_minute=25000):\n",
    "    if current_tokens >= max_tokens_per_minute:\n",
    "        sleep_time = 60  # Sleep for 60 seconds to reset the minute window\n",
    "        print(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds.\")\n",
    "        time.sleep(sleep_time)\n",
    "        current_tokens = 0  # Reset token counter after sleeping\n",
    "    return current_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store summaries\n",
    "movie_summaries = {}\n",
    "\n",
    "# Token counter\n",
    "current_tokens = 0\n",
    "\n",
    "# Iterate over each movie and summarize the reviews\n",
    "for index, row in grouped_reviews.iterrows():\n",
    "    movie_title = row['movie_title']\n",
    "    reviews = row['cleaned_review']\n",
    "    \n",
    "    summary, reviews_length = summarize_reviews(reviews)\n",
    "    movie_summaries[movie_title] = summary\n",
    "    print(f\"Summarized reviews for {movie_title}\")\n",
    "\n",
    "    # Update the token counter and manage rate limits\n",
    "    current_tokens += reviews_length + 400  # Add the length of the reviews and the max_tokens used for the summary\n",
    "    current_tokens = manage_rate_limit(current_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summaries to a JSON file\n",
    "with open('movie_summaries_final_2.json', 'w') as f:\n",
    "    json.dump(movie_summaries, f)\n",
    "\n",
    "print(\"Summarization complete. Summaries saved to movie_summaries.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
